{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context:** It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "**Content:** The dataset contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, the original features and more background information about the data is not provided. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "**Data Source:** https://www.kaggle.com/mlg-ulb/creditcardfraud/home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Care Of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We observe no missing data, we therefore move onto the next steps.\n",
    "\n",
    "ds.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** From the below bar chart and value count, we see that the number of fraud (class = 1) is disproportionality low compared to not fraud (class = 0). We must bear this in mind when we are evaluating the accuracy of the models produced using the confusion matrix. This is because, as the number of fraud is very low, we may get a very high accuracy from the confusion matrix. This however will be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Countplot of Class\n",
    "plt.suptitle('Counts Of Class')\n",
    "sns.countplot(ds.Class)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pie Chart for Fraud\n",
    "\n",
    "plt.suptitle('Fraud Pie Chart', fontsize = 20)\n",
    "plt.pie([ds[ds['Class'] == 0]['Class'].count(), ds[ds['Class'] == 1]['Class'].count()],\n",
    "            labels = ['0','1'], colors = ['r','g'], startangle = 90, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c7bcdd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJUAAAKACAYAAAAl/0nMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdf7Std10f+PcHrtTAhSSQ9BYQyfAjpkqUmqtTltLcALYrK/7sYGWIxdAp0XEYnTYImUFqwDoTbFE6oKUJtUJhuAxdtEuIVBE9UdBiSUcbfqSAeEETSQMkwUuCJeQzf5x9FyeHe+/Z32Tve743vF5rnXXu/u7v8zzv/exzz7l55/s8p7o7AAAAADDiAbsdAAAAAICTj1IJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAOArUlUdqqpn3Mttn1pV/2XVmVZ1/Ko6q6q6qvas6HgHqupPV7EvAOD+Q6kEAOyKqnp2Vb2vqg5X1Z9V1Tuq6tt3O9fRLAqaJxx53N2/091ft1t5th//vhRkW/bxrVX1q1V1W1V9pqp+v6qee9/TAgD3V0olAOCEq6p/mOSVSf7PJPuSfG2SX0zyPfdiX1+2GmdVK3S+UlTVU5L8ZpJrkzwhySOS/M9JLtzNXADA3JRKAMAJVVWnJnlZkv+lu9/a3Z/r7i9099u6+ycWc/5SVb2yqm5afLyyqv7S4rkDVfWnVfWiqvpkkn91tLHF3O+sqj9YrL753ar6xmNk+taq+r3FvD+rqldX1YMWz/32YtofLlZV/cD2y8Gq6q9W1cZi+w9U1Xdvee6Xq+oXquqaqvrzqnpvVT3+GDleV1WXLf786MUKqR9dPH7CYgVRbT1+Vf3rbJZyb1vke+GWXV5cVZ+oqk9V1YuP87b8kySv6+6Xd/enetN13f13jpHz8qr6o8Xr+WBVfd+W555QVddW1e2L4755MV5V9fNV9V8Xz/3nqnrScTIBAJNTKgEAJ9pTknx1kn97nDkvTvLXkzw5yTcl+dYkP7nl+b+S5OFJHpvk0qONVdU3J/mlJD+czZU3/yLJrxwpp7b5YpJ/kOSMRb6nJ/nRJOnuv7GY803dvbe737x1w6r6qiRvS/LrSf5ykv81yRurauvlcf9jkpcmOT3JR5P8zDFe97VJDiz+fH6Sjy0+J8nfSPI73d1bN+juv5vkE0m+a5HvZ7c8/e1Jvm7xev5RVf3V7QesqgcvXvO/OUamo/mjJE9Ncuridb2hqh65eO6ns3kuTk/yNUletRj/m4vXcHaS05L8QJJPDxwTAJiMUgkAONEekeRT3X3XceZcnORl3f1fu/uWbBYXf3fL83cn+anu/ovuvvMYY89L8i+6+73d/cXufl2Sv8hmWXUPi1U5/6G77+ruQ9ksoM7fPu8Y/nqSvUmu7O7/1t2/meTt2SySjnhrd//+4jW/MZtl2dFcm+SpVfWAbBYwP5vk2xbPnb94fsRLu/vO7v7DJH+YzYJuu9Oz+W/CP1t2p939lu6+qbvvXpRsH8lm8ZckX8hmsfeo7v58d797y/hDk5yTpLr7Q9299DEBgPkolQCAE+3TSc7Y4b5Hj0ry8S2PP74YO+KW7v78tm22jz02yWWLS9Juq6rbkjxm236SJFV1dlW9vao+WVWfzea9ns5Y8vU8KsmfdPfd2/I+esvjT2758x3ZLKG+THf/UZLD2SydnprNcuqmxaqne1MqLXPcW7NZyD3yKM8dVVU9Z8tlhbcleVK+dL5emKSS/P7iUsC/lySLsu3VSX4hyc1VdVVVPWzw9QAAE1EqAQAn2u8l+XyS7z3OnJuyWQod8bWLsSM6X2772J8k+ZnuPm3Lx4O7+01H2fafJ7khyRO7+2FJ/o9sFiPLuCnJYxari7bmvXHJ7be7Nskzkzyou29cPH5ONlcU/cExtjna+VhKd9+Rzffkf1hmflU9NsnVSZ6f5BHdfVqS92dxvrr7k939vO5+VDYvPfzFI785r7v/7+4+L8k3ZPMyuJ+4t7kBgN2nVAIATqjuvj3JP0ryC1X1vVX14Kr6qqq6sKqO3A/oTUl+sqrOrKozFvPfMHioq5P8SFX994ubRD+kqi6qqoceZe5Dk3w2yeGqOiebv/lsq5uTPO4Yx3lvks8leeHidRxI8l1JDg7mPeLabBY2R24QvpHN+zS9u7u/eIxtjpdvGS9McklV/URVPSJJquqbqupor+Eh2SyxblnMe242Vypl8fj7q+prFg9vXcz9YlV9y+K9+Kpsnq/PZ/NeVgDASUqpBACccN39c0n+YTZvvn1LNlcVPT/Jv1tM+cdJ3pfkPye5Psl/WoyNHON92byv0quzWW58NMklx5j+giTPTvLn2Syj3rzt+SuSvG5xudc9fiNad/+3JN+d5MIkn0ryi0me0903jOTd4tpsllxHSqV3J3nwlsdH839ls4S7rapeMHrA7v7dJE9bfHysqj6T5Kokv3qUuR9M8opsrm66Ocm5Sd6zZcq3JHlvVR1O8itJfry7/zjJw7J5bm/N5uWBn07yT0ezAgDzqG2/QAQAAAAAdmSlEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMP27HaAVTrjjDP6rLPOWsm+Pve5z+UhD3nISva1SrPmSubNNmuuZN5ss+ZK5s02a65k3myz5krmzTZrrmTebLPmSubNNmuuZN5ss+ZK5s02a65k3myz5krmzTZrrmTebHKNmzXbqnNdd911n+ruM7/sie6+33ycd955vSq/9Vu/tbJ9rdKsubrnzTZrru55s82aq3vebLPm6p4326y5uufNNmuu7nmzzZqre95ss+bqnjfbrLm65802a67uebPNmqt73myz5uqeN5tc42bNtupcSd7XR+lhXP4GAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAzbs9sBAOBEOevya5aad9m5d+WSHeYeuvKiVUQCAICTlpVKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAM27PbAeC+OOvya3acc9m5d+WSJeYduvKiVUQCAACArwhWKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADD1lYqVdXXV9W7quqOqrqpql5WVQ/cYZsHVdU/qarfqao7q6rXlQ8AAACAe28tpVJVnZ7kN5J0ku9J8rIklyV56Q6bPjjJ309yR5LfXUc2AAAAAO67PWva748kOSXJ3+7uzyZ5Z1U9LMkVVfWzi7Ev0923VdXDu7ur6vlJnramfAAAAADcB+u6/O3CJL+2rTw6mM2i6fzjbdjdLnkDAAAAmNy6SqVzktywdaC7P5HNy9rOWdMxAQAAADhB1lUqnZ7ktqOM37p4DgAAAICTWK3jarOq+kKSF3T3P9s2fmOSX+7uFy+xj+cneVV31w7zLk1yaZLs27fvvIMHD9774FscPnw4e/fuXcm+VmnWXMnuZLv+xtt3nLPvlOTmO3fe17mPPnUFicbM+n7OmiuZN9usuZJ5s836PSNZ7vuG7xn3NGu2WXMl82abNVcyb7ZZcyXzZps1VzJvtllzJfNmmzVXMm82ucbNmm3VuS644ILrunv/9vF13aj71iSnHWX81Bx9BdO91t1XJbkqSfbv398HDhxYyX43Njayqn2t0qy5kt3Jdsnl1+w457Jz78orrt/5S/3QxQdWkGjMrO/nrLmSebPNmiuZN9us3zOS5b5v+J5xT7NmmzVXMm+2WXMl82abNVcyb7ZZcyXzZps1VzJvtllzJfNmk2vcrNlOVK51Xf52Q7bdO6mqHpPkIdl2ryUAAAAATj7rKpXekeRvVdVDt4z9QJI7k1y7pmMCAAAAcIKsq1R6TZK/SPLWqnrG4r5HVyT5ue7+7JFJVfXRqvqXWzesqgur6plJnrx4/MzFx2PXlBUAAACAQWu5p1J331pVT0/y6iRvy+Z9lH4+m8XS9uM/cNvYP0+ytUB6y+Lzc5P88qqzAgAAADBuXTfqTnd/MMnTdphz1jJjAAAAAMxlXZe/AQAAAHA/plQCAAAAYNjaLn9j3FmXX7PjnMvOvSuXLDHv0JUXrSISAAAAwFFZqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAM27PbAQAAANbtrMuvWWreZefelUt2mHvoyotWEQngpGelEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMP89jcAADjJ+E1mAMzASiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABi2Z7cDAMzurMuv2XHOZefelUuWmHfoyotWEQkAprTMz8zEz02A+wsrlQAAAAAYplQCAAAAYJjL3wAAAIBd4VYTJzcrlQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGF7djsAAAAAwEzOuvyapeZddu5duWSJuYeuvOi+RpqSlUoAAAAADFMqAQAAADBMqQQAAADAsLXdU6mqvj7Jq5I8JcltSV6b5KXd/cUdtjs1ySuTfG82S6+3J/mx7v70urICAAAAnAyWud/TibrX01pKpao6PclvJPlgku9J8vgkr8hmSfSTO2z+5iRfl+TvJ7k7ycuT/LskT11HVgAAALg/c9Np1mVdK5V+JMkpSf52d382yTur6mFJrqiqn12MfZmqekqSv5Xk/O7+7cXYjUneW1XP6O7fWFNeAAAAuE9WWd4objgZrOueShcm+bVt5dHBbBZN5++w3c1HCqUk6e7fT/LHi+cAAAAAmMC6SqVzktywdaC7P5HkjsVzS2+38KEdtgMAAADgBFrX5W+nZ/Pm3Nvdunju3mz3uBXkAgAAmIZ73QAns+ru1e+06gtJXtDd/2zb+I1Jfrm7X3yM7d6Z5HB3f9+28TcmOau7v+0o21ya5NIk2bdv33kHDx48brbrb7x9qdew75Tk5jt3nnfuo09dan+rcvjw4ezdu/eEHtM5G7fKc7bq87VMtt14L2c+Z8vwdXZPs36dLWvW99PfzXtyzsY5Z+NmPWfL2o3vZ8uYNVcyb7ZZfzYlJ/7v5sn+3yeJr7NRs+ZK5s226lwXXHDBdd29f/v4ulYq3ZrktKOMn5qjr0Taut2ZRxk/7VjbdfdVSa5Kkv379/eBAweOG2yZdj/Z/D8Br7h+59Nz6OLjH2/VNjY2stNrXDXnbNwqz9mqz9cy2XbjvZz5nC3D19k9zfp1tqxZ309/N+/JORvnnI2b9Zwtaze+ny1j1lzJvNlm/dmUnPi/myf7f58kvs5GzZormTfbicq1rnsq3ZBt90CqqsckeUiOfs+kY263cKx7LQEAAACwC9a1UukdSX6iqh7a3X++GPuBJHcmuXaH7V5SVd/e3e9Okqran837Kb1jTVkBAADYZtn7M21sbOzKah9g962rVHpNkh9L8taqenk2S6Erkvxcd3/2yKSq+miSa7v7f0qS7v69qvq1JK+vqhckuTvJy5O8u7t/Y01ZAYBj8B8U45wzAOArxVouf+vuW5M8PckDk7wtyUuT/HySn9o2dc9izlbPyuZqpl9K8vok1yX5vgAAAAAwjXWtVEp3fzDJ03aYc9ZRxm5L8tzFBwAAAAATWlupBAAAAKvmMmOYx7p++xsAAAAA92NKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGF7djsAcGIduvKiHedsbGzk0MUH1h8GAACAk5aVSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMCwPevacVU9L8kLkzwmyQeSvLC737XDNvuTPD/JU5I8Mcnru/uSdWWEdTl05UVLzdvY2Mihiw+sNwwAAACswVpWKlXVs5K8Jsnrk1yYzVLp7VX1pB02/bYk357kPyb55DqyAQAAAHDfrevyt5cmeV13/3R3/1aSS5J8NMnlO2z3qu5+Qnf/YJKb1pQNAAAAgPto5Ze/VdXjkpyd5MePjHX33VX1lq1jR9Pdd686D8D9lcssAQCA3bSOlUrnLD7fsG38Q0keXlVnruGYAAAAAJxA1d2r3WHVxUnekOT07r5ty/gzkrwzydd194eX2M/7krx/pxt1V9WlSS5Nkn379p138ODB4+73+htv3+nQSZJ9pyQ337nzvHMffepS+1uVw4cPZ+/evSf0mM7Z+sya7WT/OjvRX2PJvO9lMu/7Oev3jMQ5uzecs3HO2ZfM/DNg1nO2rFl/Ps2aK5k326y5knmzzZormTebXONmzbbqXBdccMF13b1/+/hSl79V1alJHrnTvO7eujppe1tVxxi/T7r7qiRXJcn+/fv7wIEDx51/yeXXLLXfy869K6+4fufTc6IvKdnY2MhOr3HVnLP1mTXbyf51thuXes36Xibzvp+zfs9InLN7wzkb55x9ycw/A2Y9Z8ua9efTrLmSebPNmiuZN9usuZJ5s8k1btZsJyrXsvdU+v4kVy8xr5LcuvjzaUm2/q+d0xafb8sucg8SAAAAgPtuqXsqdfdru7t2+lhMP7Ja6ZxtuzknyWe6+5ZVhQcAAABgd6z8Rt3d/bEkH87m6qYkSVU9YPH4Has+HgAAAAAn3rKXv426IskbqupQkvck+aEkT0zy7CMTqur8JO9K8vTuvnYxdmaS8xdTTk/y2Kp6ZpJ0979ZU1YAAAAABq2lVOruN1XV3iQvSvKSJB9I8p3d/f4t0yrJA/OlG3gnyTckecuWx49LcmDLfAAAAAAmsK6VSunuq3Ocm3t390a2FUVHGwMAAABgPiu/pxIAAAAA939KJQAAAACGKZUAAAAAGKZUAgAAAGDY2m7UDQAAJ7tDV16045yNjY0cuvjA+sMAwGSsVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGDYnt0OAJAkh668aKl5GxsbOXTxgfWGAQAAYEdWKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADDMb39jR34rFwAAALDd2lYqVdXzquojVfX5qrquqp6+xDY/XFXvrKqbq+r2qnpPVf3NdWUEAAAA4N5ZS6lUVc9K8pokr09yYZIPJHl7VT1ph01fnOSPk/xwkmcm+WiSf19V372OnAAAAADcO+u6/O2lSV7X3T+dJFV1bZK/luTyJD94nO2+ubs/teXxO6vqiUn+QZJfWVNWAAAAAAatvFSqqsclOTvJjx8Z6+67q+otW8eOZluhdMT/l+TAKjMCAHwlWuY+ie6RCAAsax2Xv52z+HzDtvEPJXl4VZ05uL+nJPngfU4FAAAAwMqso1Q6ffH5tm3jt257fkdV9feyedncL64gFwAAAAArUt2986SqU5M8cqd53X1DVV2c5A1JTuvu27fs4zuS/HqSs7v7I0sc87wkv53k6u7+344z79IklybJvn37zjt48OBOu17K4cOHs3fv3pXsa5VmzZXMm23WXMm82WbNlcybbdZcye5ku/7G23ecs++U5OY7d97XuY8+dQWJxjhn45yzcbN+35j1vUyWez+9l/c0a7ZZcyXzZps1VzJvtllzJfNmk2vcrNlWneuCCy64rrv3bx9f9p5K35/k6iXmVb60Ium0JFv/hXDa4vP2FUxfvpPN+zJdk+RdSS473tzuvirJVUmyf//+PnDgwBIxd7axsZFV7WuVZs2VzJtt1lzJvNlmzZXMm23WXMnuZLvk8mt2nHPZuXflFdfv/GNoN+7t4pyNc87Gzfp9Y9b3Mlnu/fRe3tOs2WbNlcybbdZcybzZZs2VzJtNrnGzZjtRuZa6/K27X9vdtdPHYvqReymds2035yT5THffcrxjVdVfTvJrST6e5Fnd/cWB1wMAAADACbDyeyp198eSfDibq5uSJFX1gMXjdxxv26ram+RXFw+/s7vvWHU+AAAAAO67ZS9/G3VFkjdU1aEk70nyQ0memOTZRyZU1fnZvLzt6d197WL4rUm+McklSR5fVY8/Mr+7/8OasgIAAAAwaC2lUne/abHq6EVJXpLkA9lcefT+LdMqyQMXn4/4jsXnNx5lt3WUMQAAAAB2wbpWKqW7r85xbu7d3RvZVhRtuS8TAAAAABNb+T2VAAAAALj/UyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBsz24HAOD+59CVF+04Z2NjI4cuPrD+MAAAwFpYqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwTKkEAAAAwDClEgAAAADDlDjHyKgAACAASURBVEoAAAAADFMqAQAAADBMqQQAAADAMKUSAAAAAMOUSgAAAAAMUyoBAAAAMEypBAAAAMAwpRIAAAAAw5RKAAAAAAxTKgEAAAAwbM9uBwAAkkNXXrTjnI2NjRy6+MD6wwAAwBKsVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhayuVqup5VfWRqvp8VV1XVU9fYpsfrar3VdWtVXVHVV2/GKt15QQAAABg3FpKpap6VpLXJHl9kguTfCDJ26vqSTtsenqSf5vkOUm+K8nbkrw6yWXryAkAAADAvbNnTft9aZLXdfdPJ0lVXZvkryW5PMkPHmuj7v6ZbUPvqqrHZrNk+qdrygoAAADAoJWvVKqqxyU5O8n/e2Ssu+9O8pZsrloa9ekkD1pNOgAAAABWYR2Xv52z+HzDtvEPJXl4VZ250w6qak9V7a2qC7O5SukXVpwRAAAAgPtgHZe/nb74fNu28Vu3PH/LsTauqr+S5M+2DP3j7n7V6uIBAAAAcF9Vd+88qerUJI/caV5331BVFyd5Q5LTuvv2Lfv4jiS/nuTs7v7IcY61J8mTk+xNciCb92H6qe5++THmX5rk0iTZt2/feQcPHtzx9Szj8OHD2bt370r2tUqz5krmzTZrrmTebLPmSubNNmuuZN5ss+ZK5s02a65kd7Jdf+PtO87Zd0py85077+vcR5+6gkRjZn0/Z30vk+XeT+/lPc2abdZcybzZZs2VzJtt1lzJvNnkGjdrtlXnuuCCC67r7v3bx5ddqfT9Sa5eYl7lSyuSTkuy9V8Ipy0+b1/BdA/dfVeS9y0eblTV3UmuqKpXdfcdR5l/VZKrkmT//v194MCBJWLubGNjI6va1yrNmiuZN9usuZJ5s82aK5k326y5knmzzZormTfbrLmS3cl2yeXX7DjnsnPvyiuu3/mfO4cuPrCCRGNmfT9nfS+T5d5P7+U9zZpt1lzJvNlmzZXMm23WXMm82eQaN2u2E5VrqVKpu1+b5LVL7vPIvZTOSfLxLePnJPlMdx/z0rdj+E9JvjrJo5J8dHBbAOB+6tCVF+04Z2NjY1dKBgCArwQrv1F3d38syYezubopSVJVD1g8fse92OW3JfmLJDetJCAAAAAA99k6btSdJFckeUNVHUryniQ/lOSJSZ59ZEJVnZ/kXUme3t3XLsb+Y5LXJfkvSb4qyXckeX6SVxzt0jcAAAAAdsdaSqXuflNV7U3yoiQvSfKBJN/Z3e/fMq2SPHDx+Yg/SPJjSb4myR1JPpLkuUneuI6cAAAAANw761qplO6+Ose5uXd3b+SehVK6+3nrygMAAADA6qz8nkoAAAAA3P8plQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGF7djsAAABf2Q5dedFS8zY2NnLo4gPrDQMALM1KJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGFKJQAAAACGKZUAAAAAGKZUAgAAAGCYUgkAAACAYUolAAAAAIYplQAAAAAYplQCAAAAYJhSCQAAAIBhSiUAAAAAhimVAAAAABimVAIAAABgmFIJAAAAgGHV3budYWWq6pYkH1/R7s5I8qkV7WuVZs2VzJtt1lzJvNlmzZXMm23WXMm82WbNlcybbdZcybzZZs2VzJtt1lzJvNlmzZXMm23WXMm82WbNlcybbdZcybzZ5Bo3a7ZV53psd5+5ffB+VSqtUlW9r7v373aO7WbNlcybbdZcybzZZs2VzJtt1lzJvNlmzZXMm23WXMm82WbNlcybbdZcybzZZs2VzJtt1lzJvNlmzZXMm23WXMm82eQaN2u2E5XL5W8AAAAADFMqAQAAADBMqXRsV+12gGOYNVcyb7ZZcyXzZps1VzJvtllzJfNmmzVXMm+2WXMl82abNVcyb7ZZcyXzZps1VzJvtllzJfNmmzVXMm+2WXMl82aTa9ys2U5ILvdUAgAAAGCYlUoAAAAADFMqAQAAADBMqQQAAADAsD27HQCA+7+qemiSs5OcnqST3Jbkw93957sajJWoqgd29xd3O8d2VbUnyd9J8s7uvmW388yuqr46yeOT3J3ko939hV2OdFKoqjOSPDbJoe7+9C7m2JPkcUkenuSLSW7u7k/sVp6tquobkpyTe/4MuKG7P7CrwbjPFt83HpXkpu7+/G7n2aqqHpTkBUn+dXf/yW7nOaKqKkl6spsbV9V/l+Trs/kz4Pru/tMTfPx93X3ziTzmqKo6JZv3pb5jy9iTs/mz81B3X7eL2X4zyY929w1Hee7sJK/p7qet49hWKu2gqr62qp6zC8d9TFWdV1V7j/H8GbuU6wFV9eSq+tYtYw+qqkuq6mWLz6ec6FzHUlV7q+rDVfUtu53liKr6xsV5+qGqetIuZThl8R/5W8fOrKqXVtVbqurNVfW/V9WpJzjXi6rq3BN5zBGLv5c/XFU/UlWPWIx9TVW9sqreVlWv2q38VfXNVfWSqvp/qurfV9U1VfVLVfW8qjptNzItcj2jqn47+f/bO/e4zcZyj3+vYeRMUXQgKbXbKimxI5PzJpSSY1EpFaWjzVa7KMlIdhGlhHRwqFA57anJMRWGahJlMF6VcZoxI4w5vdf+47of7/LMM++88/l47nW9M7/v57M+3rWe29zfz/2sZ933fa17XYsZwI3AL4FfATcBM8zsWjPbvi2/4TCznc3s7hbq3dTMzizn1Hgz26hHmdfWdjOzd5jZz8zscjPbvRzbx8zuAeaa2YCZHVzTaQSsAvyAmMxWxcxeXiY0zWObmdlFZnaPmU0t19tNW3B7t5kd1Nhf3szGE7/TycCtxO/zvyt7zTazC83snWWimoYy1vmamU0zs/vN7LPl+BeAfxLXtwfN7DwzW6Wy2+vN7BfAv4DbgeuB3wNTzeyfZXy2ck2nhttBZjZAnFc/Id5EdEb5e3L5LbyvDbfFYWZ7mln1YLmZ7WZmvzazP5fx2LgeZbao7WZmnzKzP5rZbWZ2aDn2X8B0YApxzTiuptMIWAk4FtigdsVmtlOPsfYeZnYLMI/oNyeZ2a4tuB1uZoc39lczs/OBO4FLgMuI68fp3f1Yn7nPzG4ufutVrHexmNkaZnYx8CjwqJmdYWbLmdk5wC3ENe1GM7ve4kZDG2wDrL6Iz1YHFrqWPGO4u7ZhNmBPYEHF+p5FnJQLyjYPOBNYo6vcFjW9Sp3rAjc33H4HrA1MKvsPEZHtvwHPqej1lmG2vYrTEZ1jFb3OBTZs7K8IXFzaarBsC4AfA2Mrf5eXAyc39t9I3DWcQUz4JwKPAA8AG1f06rTJX4DPAi+r2S6Lcdu8tNF84EngPuDVwN+Be4gOeACYA2xd0WsV4KJG280rf88lAjePFO8DWmizvYvTZcABwGbEnZyXlb8PAC4tbbpX299xD/+q1/9S52bl/Jpa2mYaMBs4rKtc1T6gfJeDwG+AnwNPAAeX8+xM4CPAeeX7/s/KbXbjMNvNxfv2zrGKXguAzRv748r14W7g1LLdVb7fN1Rus9uAQxr7J5Xv9HPAVsCbgGOK22cqeg0CD5b/Pgp8n+i7l6/ZPotwO6a00UnA50sf8I1yjf0g8AbgkHK9Pb6i107lvJoEHF88ryi/zc8Bnyb61D8Cz67cZoeVPuk0YGtizLhc2dYu59mpxf8jbX/HPfzb6AN2LNeO60vbdMbdJ1He2l3K1e4DDikePwROJsaLXyjXiM8Bu5bzbw6wX+U2e3CYrTM3eaRzrKJXdx/w9uLyW2L11OHl7/nATpXb7C7gfY39s4jg4AHAC4EXAe8t3/NJFb0GiQD0vNIu1wGHAs+t2T6LcDsFeLhc1w4s19ULiXnATsBzgV2ImwzfaslxkB7jCWAFYi78j77V3fYXlH2r3aEQA5WZxGB9M+DjxMR+CrBRo1wbQaUziInODsDrgAnEIP02YP1S5hWlzFcqenUm04OL2J4WxKns1exMOoP2DxODqbXK308AR1f+Lh8G3tbY/z3wa2C1xrE1gGuACZXb7HhiMj2nfHc3AZ8EXlizjXq4/Qq4ClgTGEsM9v5BTLDHljLPIgbzV1X0+ma5Ruxe6l+uXB8mEQP5McB7SnvuXrnN/gKcMIJyXwFuq+j1+RFuF7RwnZ1Qzv/OObUC8EVicPUNyqSidh9QfoenN/bfVc6pk7rKnQ1MrNxmg8QE/6xSf3P7Ufn8is6xyl7NPuA6YqK4YuPYSuX6e1nlNnsCeHNj/0Hg4z3KHQ4M1G4zYvzzv8C95djDwOlN59obMQ77ZGN/69JHfaSr3CeJR3tred0MnNPj+GHEDY8xxE2tW4BvVm6zu4EjRlDuCODuil5njXD7dQt9wG+6r1PAQcBjxI3JFcux2n3AZOBLjf1dyvn/+a5yXwOur9xmC0of8CXg6K5tfLmGnN05VtGruw+4BbikR7nLgWsqt9lsYFxjfyaNIFPj+AeBabXbDFgH+FjpMxcQQfIJxHh29Zpt1XCbChzc2N+0+L6nq9zBwNSKXkcztOBjcdv4vnm08aVk2Jag8RdUvmj/Ffho17F1gWuJaPsby7E2gkoDzR8OEUAaBPbvKncodSeINxN3899H5DRobq8pjnt3jlX06u5M7uvufMvxL1JxAFrqfKKrM5lLj7skxJ2nx9toMyLvwgeJQd38sl1djq1Vs72Kz3Rgl8b+84rvTl3ldgUeruj1EHBgj+MbE3d61i7744EbKrfZbEYwCQTeDMyufJ79q7TdcNusFq6zD9NjpU85r/5FrEpbsXYfQKwa2aGxv0Zpx+26yu1O5NWo2WZ7EHddrwFe2/XZmsVzXE2nxnnW7AOeBN7Ro9w+wCOV3aYBezb25wDb9Ci3Ywu/zc27jo0DvkUEzxcQd4FPov7qru5A3CrF901d5bap3G/OBnbscfzZxe+VZf9AKk4OG2220HnVo9w2wBMVvRYQN4VuWsx2Zwt9wExg+x7HX19+t78lcmbV7gMeB7Zt7HfO/3Fd5Xah4mqgUuemRDDuDuCtXZ+t0cuzkld3HzAX2K1HuT2Af1V2G6Axfyu/1V7n3c6Vr2e9+oD1gSOJoNxgueZdROUV7uU38ObG/qqL6AO2BR6r6PUGYrX4R4vPiWW/uR1Mn5+iWJZzKs0BriSioMNtZ1f2Wo+4G/AU7n4/sD0xuZ5oZntUduqwDhGl7dDJ5zGlq9xtxAWgFpsRUdoTiDubY9x9wN0HiIsmwP2NY23xPCIo0s011G0viHwZ2zb2HyAGKd2sRXQ01XH3R9z9O+6+PbEM99PEqo3TiWeuL6utVLbmPl3Heu33m5WJQEQ3DxOrltYp+1cCtXN4TSEGS4tjDxa+jvSTAeB8d3/ucBvw/opOTaz7gLtfBmxHPJo0kd6/137ixPnU4bHy35ld5R4jAjnVcPefEYlFJwLXmtl3zOy5nY9ruvSgWf8cIljZzUNEoLAmvwAOb+TKmAjs16PcfsSKw9Zw92vd/RAiEfBbiFWjBxErvGryT+C1jf1Nyn+78+i9hriJVIsHGy5NNiHOv1llf4CYYNdkMnCwmS1yvmFmRkx4Ji+qTB+YAlzp7m8YbgOq5hQrPEkEbJ6GR/LfrYhHbH4LvKSy1xxivNGhk5D7sa5y87rK9R13/4O7v4nInfQtM/uVmf17TYdhaPYBs1i4vSCCFbXn5OcD/9PJD0oEaT5iZk/18xaJ/w8lVr63hrvf6+4nuPvriPyIJ5T/nl9ZZSpxE7TD1kQQZ8uuclsRq2yr4O43uftp7n4qscDihLLf3M5w9+v66bEsv/1tEjDf3U8brpCZ7Ul8QbW4D9iIWJn0FB5vYNnXzL5O5Fz6fkWnDtOJQV2H+cRSxBld5dZkqLPpOx5h2u+Y2Y+Jpa+TzezU8nfbbNlI1jad3snTViei7jUZD/zIzP5OnEvHASea2XQiyGVE0Ol4IudTq5TA6snAyWb2YmKis09ljZuJSdj1xADgM8Qk4xAzu9LdFzQ64Fsrel0PHGlm13l5k1oZFBxDDGA6wZrlqX+efQ74aUle/mNiJeZMYpC1JjEo2Iu4S/3Oil6/A/5jBOWcHgGePnMbcRPh/xaScb/JzLYun/2ostcAEbiZUFwWmNkbiVxFTTYE7q/shrvPAY4tCTNPAqaY2bG001c2+Z6ZPV7+Xo5ow+6B3cuIwEBNjioet5rZd4nErCdYvDzi6lJmO2IFwO6V3Xri8XbBCcCEEgzbpbLCD4DjzOyFxMq9DxGPpB5rZnOAPxGpAY4BvlvR6zvFYRXi5uNc4s71Z4lHsTsBrg2pONEpfJq4Xt1mZhfRuw94O3HjaOeKXr9n4YlgL9roAyYT5/YvFpJxv9vMtiIel/peZa+7iIDpZcVlgZk9n4Vvar2CWAVWHXf/QUmkfDRwk5mdRTyO1yYTzGx++XsNIjB9dVeZfyNWodXkGGK12x1l/nQ7sRrorjLOhch5thqR9iQF7n4H4X6MmfUKpveT04l5yKuJ8fXeRF/6eYsXa3X6gE8SAc7quPs5bdTbqXyZ3IilYTNGUG5n6j4XeTZw9WLKHEXl/ECl3iuA00ZQ7njguha/29cQF+z7iJxUC2hv2Wv3dkqPcl+lYvLYRr0fIAbGs4jcWI8y9Mjn/PLfi4GVK7fZ5rXqW0K3zYhEj/OI4Mx04k7wFGLV3iXEXYw5NJaIV/DamFhpNpNYbXA5EeyaB7y3UW48FfNjNep9EzERnNO5bjGU52wOMeHYqrLTDsBXR1Bufbqela/gdiQRqF9jmDLPJ5Lu1nz04RhGkKyTmNR+v2abLcJjW2JyNtBiH3B2j+2wHuWuBX7agt9q5bpwf4++6slyTav9iFnmPmAssRp6GjGRHl+OH8FQDsBB4o7/qpXdjip9eTOX5A8pjz+XMu+mx6PSFdxeCny7/Ba7z7MBYqL20spOrwc+NoJya1M5jxcRrBxgmBfeECuZfgkMVvQ6hBEk7SfGk9+u2WaL8HgFMW/pjG3b6AOO7rHt36Pc1cAZLfiNIXK73kAEo5u/zalE0Hz9yk5TgU3aPn+G8fsYcWNyEvDhcmw/hhLCP1b6iaovYGr4jWUoAfy99Ehe36+6Owk/lznMbCwxWZ612MIVMbPNiTv34919+jDl9ieeoa+2iqpEZldx92GXnJvZicAkd7+gktdYj5Vc3cf3JRIAv4h4pv/ahf7n/nq9nBhoNpnjseqmWe5o4K+12qvUOdbd55Vlr/sQSfHWJTqYGcQdi0s9lltXw8y+DJzqQ3dW01CuGesQuW3GAhe6+zQzW5eYVLyCGAh+191vqey1EvHM9CbEYzR3EgOUvzXKrUYEIVp5nLGsLHgpkecDIkB3l7vPbcMnK+UxkZWIPDaDw5RbEVjH232kdyHMbH1gprs/msBlOSIH28uBb7j73Yv5X1rBzFYn+obu/qKmwwY8vQ+4q1e/KnpT+tINiaTmtVeddRzGEtfYFYmk163/Brsxs5UZejx2Zlv9kVh2MLNdiD7gJxnHllko14+1iD7gEXevvbJ9VFMe413b3Xs94l7T41QiMH0psfJ9oTG2u3+hL3Uvw0Gl6cRrAM8jVgalaAgzm8GQ11VZvCB1my3SqzyOtAqRMG1BFq+2yepWzv+fkswLntZm55Pot5nVSwghhBBCCFEHM3uAeAP7SbXrXpYTdZ9H5AmYCPzTzL5WVgm1zbnAbkQiykxekLfNenltAeDu8919Vu2A0jBeGdoLhtx+TS63c8nfZtl+m1m9RoyZrW9mB7bt0U1WL8jrltUL8rpl9YK8blm9IK9bm15mtp6Zvb7kHen1+dptuGX1KnWndMvqVepO6ZbVq9Sd0i2rV6k7rRuRA67mSw+GaON5vywbEVTbgUio+DDxzO3dRILnV8lr9LjJa+lxy+qV2S2r1xL470nlHHGj2SuzW1avzG5ZvTK7ZfXK7NaGF/As4uUynVx684Az6coZRyQMrpkjLqVXZresXpndsnpldsvqld2tUfdxwFlt1L0sr1TC3QfdfaK7f4DIJfA24k1KhwF/MrNbzewoM9tQXrnd5LX0uGX1yuyW1UsIIcQyzZHAjkQy4C2IBLK7AZPMbCN59SSrW1YvyOuW1QvyumX1gtxuHR4AtjOzq8zsM2Z2aNd2SN9qbiOSlX0jIpHvIHK7zAfmt+2U2Suzm7yWHresXpnd2vZi6G7OiLZl3SuzW1avzG5ZvTK7ZfXK7JbVq7j9Ffho17F1iTcePgS8sRyrvRoipVdmt6xemd2yemV2y+qV3a3h0+vN482tb17LI3qxKTAO2JJ4rOSeVm2GyOoFed3kteRkdcvqBXnd2vaaQ6yY+tliym0KVHuTJXm9IK9bVi/I65bVC/K6ZfWCvG5ZvQDWoyu/h7vfb2bbAz8AJprZu4Bp8krvltUrs1tWr8xuWb2yu3V82nsKrY0oWsaN6GxPAKYSd3OmAadQoo7yGj1u8lp63LJ6ZXbL5EXcvbliBOWq5vrI6pXZLatXZresXpndsnpldsvqVeqcArx/mM+/zlBekpptltIrs1tWr8xuWb0yu2X1yu6WYVumVyqZ2SuBfYF9gI2AWcDFxNuUrnT3QXmNDjd5LT1uWb0yu2X1Am4A3j+Cco8D9/bZpUlWL8jrltUL8rpl9YK8blm9IK9bVi+A3wAHEJOshXD3T1i8Avs4wOUF5HXL6gV53bJ6QV63rF6Q2w0AM3vL4sq4++V9qbtE1pY5zGwysDEwG7iUmHxd4e5z5dWbrG7yWnKyumX1grxuWb0AzGwssLK7z2rbpUlWL8jrltUL8rpl9YK8blm9IK9bVi8AM9sc2AsY7+7Thym3P7Cju1d5PC+rV2a3rF6Z3bJ6ZXbL6pXdrVH3IBHQsq6Pngr4uPtyfal7GQ4qXUJMvn7u7o+37dMhqxfkdZPXkpPVLasX5HXL6gVgZtOBCwm/qz1Jh5PVC/K6ZfWCvG5ZvSCvW1YvyOuW1QvAzGYw5HZVFresXpDXLasX5HXL6gV53bJ6QW63Dmb24h6HnwPsBLwXeJ+7/74vdSdsDyGEEEsBZnYqkcfjecRrTi8AznP3G+XVm6xuWb0gr1tWL8jrltUL8rpl9YK8blm9IK9bVi/I65bVC/K6ZfWC3G4jwcwOB8a5+1v78u8rqCSEEKJfmNkYYDsi59MewLOBAeBc4Hx3v1Veo8Mtq1dmt6xemd2yemV2y+qV2S2rV2a3rF6Z3bJ6ZXbL6pXdbXGUt9T93N1X7cu/r6CSEEKIGpjZ8sDORELxtwKrArcDPwIucPe75TU63LJ6ZXbL6pXZLatXZresXpndsnpldsvqldktq1dmt6xe2d26MbMViATj/+HuG/WlDgWVhBBC1MbMngXsCuxP3O3B3Vt/I2lWL8jrltUL8rpl9YK8blm9IK9bVi/I65bVC/K6ZfWCvG5ZvSCvW1YvyONmZjex8JvnVgA2AFYjcip9vx91p/gihBBCLHNsCowDtgTGAPe0ajNEVi/I65bVC/K6ZfWCvG5ZvSCvW1YvyOuW1QvyumX1grxuWb0gr1tWL8jj9hcWDio9CfwE+Jm7/6VfFWulkhBCiCqY2abEc+h7A+sDDxId3Xnu/jt5jR63rF6Z3bJ6ZXbL6pXZLatXZresXpndsnpldsvqldktq1d2tzbQSiUhhBB9w8xeSXS6+wAbAbOAi4lXsl7p7oPyGh1uWb0yu2X1yuyW1SuzW1avzG5ZvTK7ZfXK7JbVK7NbVq/sbk1KDqVXA88BZgB/dve5fa1TK5WEEEL0AzObDGwMzAYuJTrdK/rdsY1WL8jrltUL8rpl9YK8blm9IK9bVi/I65bVC/K6ZfWCvG5ZvSCvW1YvyO3WxMyOAI4CVgesHJ4FfNndT+xXvVqpJIQQol8MAOOJV5g+3rZMg6xekNctqxfkdcvqBXndsnpBXresXpDXLasX5HXL6gV53bJ6QV63rF6Q2w0AM/sEcDxwOnAB8ACwDrGy6ngzm+Pup/Slbq1UEkIIIYQQQgghhBidmNkU4Mfu/tkenx0H7OPuL+tH3WP68Y8KIYQQQgghhBBCiCqsB1y1iM+uBl7Ur4oVVBJCCCGEEEIIIYQYvdwL7LSIz3Ysn/cF5VQSQgghhBBCCCGEGL2cApxiZs8BfkrkVHoesBfwXuBj/apYOZWEEEIIIYQQQgghRjFmdjBwNPACwIk3wN0HHOPu3+1bvQoqCSGEEEIIIYQQQoxuzMyI/EnPB6YB//A+B30UVBJCCCGEEEIIIYQQS4xyKgkhhBBCCCGEEEKMYszsBcDuwAuBFbs+dnc/si/1aqWSEEIIIYQQQgghxOjEzPYFziHyKD0EzO0q4u6+YV/qVlBJCCGEEEIIIYQQYnRiZncBNwAfdvdHa9Y9pmZlQgghhBBCCCGEEOIZZS3gzNoBJVBQSQghhBBCCCGEEGI0cxGwTRsV6/E3IYQQQgghhBBCiFGKma0MnAk8DlwJzOwu4+6X96VuBZWEEEIIIYQQ5DkjZwAAAk5JREFUQgghRidm9lrgQuAliyji7r5cP+pevh//qBBCCCGEEEIIIYSowtnAo8CuwJ0s/Pa3vqGVSkIIIYQQQgghhBCjFDN7HHiHu0+oXbcSdQshhBBCCCGEEEKMXm4E1m+jYj3+JoQQQgghhBBCCDF6+RTwPTObzaITdT/Rj4r1+JsQQgghhBBCCCHEKMXMBsufiwzwKFG3EEIIIYQQQgghhOjmIIYJKAEr9KtirVQSQgghhBBCCCGEWIowMwO2BfYjkniv1Y96tFJJCCGEEEIIIYQQYinAzLYgAkl7A+sAM4Dz+1WfgkpCCCGEEEIIIYQQoxQzexURSNoX2ACYSzzy9ingNHef36+6x/TrHxZCCCGEEEIIIYQQzzxmtqGZfcbM/gz8CTgcuB04ENgIMOAP/QwogVYqCSGEEEIIIYQQQow27iSSc98AfAi40N0fATCzNWpJaKWSEEIIIYQQQgghxOhigFiN9CpgG2BLM6u+cEhBJSGEEEIIIYQQQohRhLu/BNgKOAfYHrgEeMDMzij7XsPD3KvUI4QQQgghhBBCCCGeYcxsDBFI2g/YA1iTCCqdC5zs7pP6VreCSkIIIYQQQgghhBCjHzNbAXgL8Sa43YCVgDvc/ZV9qU9BJSGEEEIIIYQQQoilCzNbhVi5tK+7796XOhRUEkIIIYQQQgghhBBLihJ1CyGEEEIIIYQQQoglRkElIYQQQgghhBBCCLHEKKgkhBBCCCGEEEIIIZYYBZWEEEIIIYQQQgghxBKjoJIQQgghhBBCCCGEWGL+H/ETviIjyMVhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example observations/interpretations\n",
    "\n",
    "# The lower V1, V3, V7, V10, V12, V14, V16 and V17 are, the higher the probability of fraud (and vice versa).\n",
    "# The higher V2, V4 and V11 are, the higher the probability of fraud.\n",
    "\n",
    "ds.drop(columns = ['Class','Time']).corrwith(ds.Class).plot.bar(\n",
    "        figsize = (20,10), title = 'Correlation with Class', fontsize = 15, rot = 90, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1d423668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix of independent variables\n",
    "\n",
    "sns.set(style = 'white', font_scale = 1.1) # Builds the background\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = ds.drop(columns = ['Class','Time']).corr() #Â Creating a 2D array of each correlation feature to each other\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True # This creates a the lower diagonal of the matrix as it is symmetrical\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, axes = plt.subplots(figsize = (9,9)) # Size of the plot\n",
    "fig.suptitle(\"Correlation Matrix\", fontsize = 40) # Title\n",
    "\n",
    "# Generate a custom diverging colourmap\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap = True) # Colouring\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "\n",
    "sns.heatmap(corr, mask = mask, cmap = cmap, vmax = 0.4, center = 0, \n",
    "            square = True, linewidth = 0.5, cbar_kws = {'shrink': 0.5})\n",
    "\n",
    "# The only correlation between variables appears to be with the Amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe no categorical variables, we therefore move onto the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting The Dataset Into The Training Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop(columns = ['Class','Time'])\n",
    "y = ds.Class\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is a compulsory step because there will be a high volume of computations due to the ANN, making this highly computationally intensive. Feature Scaling will therefore ease the calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The Standard Scaler returns a numpy array of multiple dimensions. The problem with this process is that it loses the column names and index. The index is how we identify each set of fields to the user, and we would like the column names to be built within our model. We therefore save the scaled part into a different data frame by converting the result of the Standard Scaler into its data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>161145</td>\n",
       "      <td>-0.067419</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>-0.427936</td>\n",
       "      <td>-0.703358</td>\n",
       "      <td>1.326641</td>\n",
       "      <td>1.310295</td>\n",
       "      <td>0.405967</td>\n",
       "      <td>0.523780</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>-0.333149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081846</td>\n",
       "      <td>-0.084033</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.400190</td>\n",
       "      <td>-4.075975</td>\n",
       "      <td>-1.707847</td>\n",
       "      <td>0.700556</td>\n",
       "      <td>0.764065</td>\n",
       "      <td>0.230267</td>\n",
       "      <td>-0.165692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204520</td>\n",
       "      <td>1.082570</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>-0.997703</td>\n",
       "      <td>0.080656</td>\n",
       "      <td>0.438362</td>\n",
       "      <td>-0.250646</td>\n",
       "      <td>0.163260</td>\n",
       "      <td>-0.216420</td>\n",
       "      <td>0.348360</td>\n",
       "      <td>0.025064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.443008</td>\n",
       "      <td>-1.083154</td>\n",
       "      <td>0.425957</td>\n",
       "      <td>0.108640</td>\n",
       "      <td>-0.261294</td>\n",
       "      <td>0.423242</td>\n",
       "      <td>-0.170159</td>\n",
       "      <td>-0.177600</td>\n",
       "      <td>-0.352239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182659</td>\n",
       "      <td>-0.044312</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>1.038206</td>\n",
       "      <td>0.484460</td>\n",
       "      <td>0.163547</td>\n",
       "      <td>0.830015</td>\n",
       "      <td>1.285435</td>\n",
       "      <td>-0.904559</td>\n",
       "      <td>0.692978</td>\n",
       "      <td>1.284152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>1.461864</td>\n",
       "      <td>-0.652606</td>\n",
       "      <td>1.193401</td>\n",
       "      <td>-0.330270</td>\n",
       "      <td>-1.273134</td>\n",
       "      <td>-2.996064</td>\n",
       "      <td>-3.509166</td>\n",
       "      <td>0.330886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25117</td>\n",
       "      <td>0.688562</td>\n",
       "      <td>-0.321167</td>\n",
       "      <td>0.367027</td>\n",
       "      <td>-0.444613</td>\n",
       "      <td>-0.834837</td>\n",
       "      <td>-0.641813</td>\n",
       "      <td>-0.523043</td>\n",
       "      <td>-0.025306</td>\n",
       "      <td>-0.594087</td>\n",
       "      <td>0.565382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087169</td>\n",
       "      <td>-0.019907</td>\n",
       "      <td>-0.247870</td>\n",
       "      <td>0.283512</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.290527</td>\n",
       "      <td>-0.839004</td>\n",
       "      <td>0.034343</td>\n",
       "      <td>0.049675</td>\n",
       "      <td>-0.336067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227642</td>\n",
       "      <td>-0.777711</td>\n",
       "      <td>0.392471</td>\n",
       "      <td>0.406750</td>\n",
       "      <td>-0.396458</td>\n",
       "      <td>0.612566</td>\n",
       "      <td>-0.386884</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>-0.078732</td>\n",
       "      <td>-0.057029</td>\n",
       "      <td>-0.947040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095765</td>\n",
       "      <td>-0.297961</td>\n",
       "      <td>-0.540302</td>\n",
       "      <td>-0.341308</td>\n",
       "      <td>0.971565</td>\n",
       "      <td>1.303022</td>\n",
       "      <td>1.076139</td>\n",
       "      <td>0.162199</td>\n",
       "      <td>0.453377</td>\n",
       "      <td>0.005211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "161145 -0.067419  0.066209 -0.427936 -0.703358  1.326641  1.310295  0.405967   \n",
       "204520  1.082570  0.010195 -0.997703  0.080656  0.438362 -0.250646  0.163260   \n",
       "182659 -0.044312  0.101926  1.038206  0.484460  0.163547  0.830015  1.285435   \n",
       "25117   0.688562 -0.321167  0.367027 -0.444613 -0.834837 -0.641813 -0.523043   \n",
       "227642 -0.777711  0.392471  0.406750 -0.396458  0.612566 -0.386884  0.803575   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "161145  0.523780  0.015398 -0.333149  ... -0.081846 -0.084033  0.007304   \n",
       "204520 -0.216420  0.348360  0.025064  ... -0.112308 -0.443008 -1.083154   \n",
       "182659 -0.904559  0.692978  1.284152  ...  0.068198  0.020632  1.461864   \n",
       "25117  -0.025306 -0.594087  0.565382  ... -0.087169 -0.019907 -0.247870   \n",
       "227642 -0.078732 -0.057029 -0.947040  ... -0.095765 -0.297961 -0.540302   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "161145  0.400190 -4.075975 -1.707847  0.700556  0.764065  0.230267 -0.165692  \n",
       "204520  0.425957  0.108640 -0.261294  0.423242 -0.170159 -0.177600 -0.352239  \n",
       "182659 -0.652606  1.193401 -0.330270 -1.273134 -2.996064 -3.509166  0.330886  \n",
       "25117   0.283512  0.573864  0.290527 -0.839004  0.034343  0.049675 -0.336067  \n",
       "227642 -0.341308  0.971565  1.303022  1.076139  0.162199  0.453377  0.005211  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 29)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 29)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Fitting The Artificial Neural Network To The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import keras # Keras wraps Theano and Tensorflow libraries together.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mohitgoel/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 16, input_dim = 29, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 24, activation = 'relu', init = 'uniform'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 20, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 24, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 1, activation = 'sigmoid', init = 'uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mohitgoel/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "199364/199364 [==============================] - 25s 124us/step - loss: 0.0085 - accuracy: 0.9988\n",
      "Epoch 2/5\n",
      "199364/199364 [==============================] - 24s 122us/step - loss: 0.0043 - accuracy: 0.9994\n",
      "Epoch 3/5\n",
      "199364/199364 [==============================] - 24s 122us/step - loss: 0.0039 - accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "199364/199364 [==============================] - 25s 127us/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "199364/199364 [==============================] - 26s 132us/step - loss: 0.0036 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a1d4081d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the ANN\n",
    "# Optimizer = 'adam': The algorithm used to find the optimal set of weights in the ANN.\n",
    "# Loss: The loss function within the stochastic gradient descent algorithm (within the adam algorithm).\n",
    "# Loss = 'binary_crossentropy': Binary outcomes\n",
    "# Loss = 'categorical_crossentropy': Three or more categories.\n",
    "# metrics = 'accuracy': The criterion we use to evaluate our model.\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 15, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Predicting the test set results\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85443/85443 [==============================] - 1s 17us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0033960980691473876, 0.9994031190872192]\n"
     ]
    }
   ],
   "source": [
    "# From the below, we observe that we have achieved 99.94% accuracy in our model.\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85274    22]\n",
      " [   29   118]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.84      0.80      0.82       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.90      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999403110845827"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222996515679442"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a function of precision_score and recall_score, and it balances them out.\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428571428571429"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8027210884353742"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist (Frauds), how many did we predict as true.\n",
    "# Moreover the confusion matrix, this metric gives us a clearer picture of the reliabilty of the model.\n",
    "# This is due to Fraud transactions potentially having devastating consequences to people.\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996600354032097\n"
     ]
    }
   ],
   "source": [
    "#Â Specificity\n",
    "\n",
    "print(cm[0,0]/(cm[0,0] + cm[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[284284     31]\n",
      " [   273    219]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting for the whole dataset\n",
    "\n",
    "X = ds.drop(columns = ['Class','Time'])\n",
    "y = ds.Class\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "y_pred = y_pred > 0.5\n",
    "y_expected = y\n",
    "cm_all = confusion_matrix(y_expected, y_pred)\n",
    "print(cm_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ds = ds.drop(columns = ['Time','Class'])\n",
    "y_ds = ds.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X_ds = StandardScaler()\n",
    "\n",
    "X_ds_scaled = pd.DataFrame(sc_X_ds.fit_transform(X_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ds_scaled.columns = X_ds.columns.values\n",
    "X_ds_scaled.index = X_ds.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>0.083386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>-0.153350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>-0.050468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>0.691625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284802</td>\n",
       "      <td>-6.065842</td>\n",
       "      <td>6.099286</td>\n",
       "      <td>-6.486245</td>\n",
       "      <td>-1.459641</td>\n",
       "      <td>-3.886611</td>\n",
       "      <td>-1.956690</td>\n",
       "      <td>-3.975628</td>\n",
       "      <td>6.116573</td>\n",
       "      <td>1.742559</td>\n",
       "      <td>4.000715</td>\n",
       "      <td>...</td>\n",
       "      <td>1.914365</td>\n",
       "      <td>0.290602</td>\n",
       "      <td>0.154146</td>\n",
       "      <td>1.624574</td>\n",
       "      <td>-0.841000</td>\n",
       "      <td>2.756320</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>2.337901</td>\n",
       "      <td>2.495529</td>\n",
       "      <td>-0.350151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284803</td>\n",
       "      <td>-0.374121</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>1.342145</td>\n",
       "      <td>-0.521651</td>\n",
       "      <td>0.629040</td>\n",
       "      <td>0.794446</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.246886</td>\n",
       "      <td>0.532299</td>\n",
       "      <td>-0.896292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.291625</td>\n",
       "      <td>1.273781</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-1.677920</td>\n",
       "      <td>-1.163726</td>\n",
       "      <td>-0.819647</td>\n",
       "      <td>0.169641</td>\n",
       "      <td>-0.162164</td>\n",
       "      <td>-0.254117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284804</td>\n",
       "      <td>0.980024</td>\n",
       "      <td>-0.182434</td>\n",
       "      <td>-2.143205</td>\n",
       "      <td>-0.393984</td>\n",
       "      <td>1.905833</td>\n",
       "      <td>2.275262</td>\n",
       "      <td>-0.239939</td>\n",
       "      <td>0.593140</td>\n",
       "      <td>0.393630</td>\n",
       "      <td>-0.445225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.315913</td>\n",
       "      <td>0.796788</td>\n",
       "      <td>-0.060053</td>\n",
       "      <td>1.056944</td>\n",
       "      <td>0.509797</td>\n",
       "      <td>-0.181182</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>-0.080467</td>\n",
       "      <td>-0.081839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284805</td>\n",
       "      <td>-0.122755</td>\n",
       "      <td>0.321250</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.487192</td>\n",
       "      <td>-0.273836</td>\n",
       "      <td>0.468155</td>\n",
       "      <td>-0.554672</td>\n",
       "      <td>0.568631</td>\n",
       "      <td>0.356887</td>\n",
       "      <td>-0.366558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165300</td>\n",
       "      <td>0.361112</td>\n",
       "      <td>1.102451</td>\n",
       "      <td>-0.261503</td>\n",
       "      <td>0.203428</td>\n",
       "      <td>-1.091855</td>\n",
       "      <td>1.133635</td>\n",
       "      <td>0.269604</td>\n",
       "      <td>0.316687</td>\n",
       "      <td>-0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284806</td>\n",
       "      <td>-0.272331</td>\n",
       "      <td>-0.114899</td>\n",
       "      <td>0.463866</td>\n",
       "      <td>-0.357570</td>\n",
       "      <td>-0.009089</td>\n",
       "      <td>-0.487602</td>\n",
       "      <td>1.274769</td>\n",
       "      <td>-0.347176</td>\n",
       "      <td>0.442532</td>\n",
       "      <td>-0.840730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496739</td>\n",
       "      <td>0.355411</td>\n",
       "      <td>0.886149</td>\n",
       "      <td>0.603365</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.908631</td>\n",
       "      <td>-1.696853</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.514355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068  0.193679   \n",
       "1       0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820 -0.063700   \n",
       "2      -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454  0.639776   \n",
       "3      -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150  0.192071   \n",
       "4      -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999  0.479302   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802 -6.065842  6.099286 -6.486245 -1.459641 -3.886611 -1.956690 -3.975628   \n",
       "284803 -0.374121 -0.033356  1.342145 -0.521651  0.629040  0.794446  0.019667   \n",
       "284804  0.980024 -0.182434 -2.143205 -0.393984  1.905833  2.275262 -0.239939   \n",
       "284805 -0.122755  0.321250  0.463320  0.487192 -0.273836  0.468155 -0.554672   \n",
       "284806 -0.272331 -0.114899  0.463866 -0.357570 -0.009089 -0.487602  1.274769   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "0       0.082637  0.331128  0.083386  ...  0.326118 -0.024923  0.382854   \n",
       "1       0.071253 -0.232494 -0.153350  ... -0.089611 -0.307377 -0.880077   \n",
       "2       0.207373 -1.378675  0.190700  ...  0.680975  0.337632  1.063358   \n",
       "3       0.316018 -1.262503 -0.050468  ... -0.269855 -0.147443  0.007267   \n",
       "4      -0.226510  0.744326  0.691625  ...  0.529939 -0.012839  1.100011   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284802  6.116573  1.742559  4.000715  ...  1.914365  0.290602  0.154146   \n",
       "284803  0.246886  0.532299 -0.896292  ...  0.077330  0.291625  1.273781   \n",
       "284804  0.593140  0.393630 -0.445225  ...  0.001811  0.315913  0.796788   \n",
       "284805  0.568631  0.356887 -0.366558  ...  0.165300  0.361112  1.102451   \n",
       "284806 -0.347176  0.442532 -0.840730  ...  0.496739  0.355411  0.886149   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "0      -0.176911  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1       0.162201 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2       1.456320 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3      -0.304777 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4      -0.220123  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "284802  1.624574 -0.841000  2.756320  0.518500  2.337901  2.495529 -0.350151  \n",
       "284803  0.019958 -1.677920 -1.163726 -0.819647  0.169641 -0.162164 -0.254117  \n",
       "284804 -0.060053  1.056944  0.509797 -0.181182  0.011037 -0.080467 -0.081839  \n",
       "284805 -0.261503  0.203428 -1.091855  1.133635  0.269604  0.316687 -0.313249  \n",
       "284806  0.603365  0.014526 -0.908631 -1.696853 -0.005984  0.041350  0.514355  \n",
       "\n",
       "[284807 rows x 29 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ds_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n"
     ]
    }
   ],
   "source": [
    "fraud_indices = np.array(ds[ds.Class == 1].index)\n",
    "fraud_count = len(fraud_indices)\n",
    "print(fraud_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fraud_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284315\n"
     ]
    }
   ],
   "source": [
    "not_fraud_indices = ds[ds.Class == 0].index\n",
    "print(len(not_fraud_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n"
     ]
    }
   ],
   "source": [
    "random_not_fraud_indices = np.random.choice(not_fraud_indices, size = fraud_count, replace = False)\n",
    "random_not_fraud_indices = np.asarray(random_not_fraud_indices)\n",
    "print(len(random_not_fraud_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984\n"
     ]
    }
   ],
   "source": [
    "undersampling_indices = np.concatenate([fraud_indices, random_not_fraud_indices])\n",
    "print(len(undersampling_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample_data = ds.loc[undersampling_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6108</td>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6329</td>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41357</td>\n",
       "      <td>40648.0</td>\n",
       "      <td>-1.825014</td>\n",
       "      <td>-4.993696</td>\n",
       "      <td>-0.189945</td>\n",
       "      <td>2.385365</td>\n",
       "      <td>-2.613531</td>\n",
       "      <td>0.878926</td>\n",
       "      <td>0.928945</td>\n",
       "      <td>0.103313</td>\n",
       "      <td>0.504453</td>\n",
       "      <td>...</td>\n",
       "      <td>1.224577</td>\n",
       "      <td>0.093147</td>\n",
       "      <td>-1.314878</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>-0.385377</td>\n",
       "      <td>-0.391447</td>\n",
       "      <td>-0.207192</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210385</td>\n",
       "      <td>137958.0</td>\n",
       "      <td>1.854299</td>\n",
       "      <td>-0.804771</td>\n",
       "      <td>-0.360653</td>\n",
       "      <td>0.307561</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>-0.612821</td>\n",
       "      <td>-0.659577</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>1.736695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208613</td>\n",
       "      <td>0.642849</td>\n",
       "      <td>0.102294</td>\n",
       "      <td>-0.006852</td>\n",
       "      <td>-0.260221</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>74.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163976</td>\n",
       "      <td>116360.0</td>\n",
       "      <td>0.601129</td>\n",
       "      <td>0.356987</td>\n",
       "      <td>-0.510714</td>\n",
       "      <td>1.289622</td>\n",
       "      <td>0.106832</td>\n",
       "      <td>-0.735212</td>\n",
       "      <td>0.519255</td>\n",
       "      <td>-1.168792</td>\n",
       "      <td>-0.224173</td>\n",
       "      <td>...</td>\n",
       "      <td>1.173542</td>\n",
       "      <td>0.757944</td>\n",
       "      <td>-0.237127</td>\n",
       "      <td>0.064808</td>\n",
       "      <td>0.111113</td>\n",
       "      <td>-0.353740</td>\n",
       "      <td>0.306467</td>\n",
       "      <td>0.371193</td>\n",
       "      <td>135.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244940</td>\n",
       "      <td>152544.0</td>\n",
       "      <td>-0.062028</td>\n",
       "      <td>0.913199</td>\n",
       "      <td>-1.047768</td>\n",
       "      <td>-0.214290</td>\n",
       "      <td>0.241072</td>\n",
       "      <td>-0.918998</td>\n",
       "      <td>0.507371</td>\n",
       "      <td>0.391584</td>\n",
       "      <td>-0.147832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369838</td>\n",
       "      <td>0.862188</td>\n",
       "      <td>-0.075964</td>\n",
       "      <td>-0.469764</td>\n",
       "      <td>-0.393814</td>\n",
       "      <td>-0.146159</td>\n",
       "      <td>-0.034206</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>42.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129029</td>\n",
       "      <td>78928.0</td>\n",
       "      <td>-0.423274</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>1.275924</td>\n",
       "      <td>-0.100393</td>\n",
       "      <td>0.225001</td>\n",
       "      <td>-0.199352</td>\n",
       "      <td>0.494028</td>\n",
       "      <td>0.243301</td>\n",
       "      <td>-0.576328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191703</td>\n",
       "      <td>-0.506845</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>-0.048048</td>\n",
       "      <td>-0.282060</td>\n",
       "      <td>0.086128</td>\n",
       "      <td>0.255237</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623        472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "41357    40648.0 -1.825014 -4.993696 -0.189945  2.385365 -2.613531  0.878926   \n",
       "210385  137958.0  1.854299 -0.804771 -0.360653  0.307561 -1.054221 -0.612821   \n",
       "163976  116360.0  0.601129  0.356987 -0.510714  1.289622  0.106832 -0.735212   \n",
       "244940  152544.0 -0.062028  0.913199 -1.047768 -0.214290  0.241072 -0.918998   \n",
       "129029   78928.0 -0.423274  0.999931  1.275924 -0.100393  0.225001 -0.199352   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "41357   0.928945  0.103313  0.504453  ...  1.224577  0.093147 -1.314878   \n",
       "210385 -0.659577  0.017778  1.736695  ...  0.208613  0.642849  0.102294   \n",
       "163976  0.519255 -1.168792 -0.224173  ...  1.173542  0.757944 -0.237127   \n",
       "244940  0.507371  0.391584 -0.147832  ...  0.369838  0.862188 -0.075964   \n",
       "129029  0.494028  0.243301 -0.576328  ... -0.191703 -0.506845  0.005441   \n",
       "\n",
       "             V24       V25       V26       V27       V28   Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276     0.00      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764   529.00      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029   239.93      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573    59.00      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793     1.00      1  \n",
       "...          ...       ...       ...       ...       ...      ...    ...  \n",
       "41357   0.263500 -0.385377 -0.391447 -0.207192  0.287554  1500.00      0  \n",
       "210385 -0.006852 -0.260221  0.126185 -0.002983 -0.033980    74.95      0  \n",
       "163976  0.064808  0.111113 -0.353740  0.306467  0.371193   135.86      0  \n",
       "244940 -0.469764 -0.393814 -0.146159 -0.034206  0.022906    42.81      0  \n",
       "129029 -0.048048 -0.282060  0.086128  0.255237  0.083369     2.28      0  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 31)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample_data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting The Dataset Into The Training Set And Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = under_sample_data.drop(columns = ['Class','Time'])\n",
    "y = under_sample_data.Class\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6870</td>\n",
       "      <td>0.097919</td>\n",
       "      <td>0.438841</td>\n",
       "      <td>-0.163548</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>-0.138751</td>\n",
       "      <td>-0.897668</td>\n",
       "      <td>-0.278711</td>\n",
       "      <td>0.267664</td>\n",
       "      <td>-0.073018</td>\n",
       "      <td>-0.959436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163835</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>-0.431794</td>\n",
       "      <td>0.051063</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>0.572728</td>\n",
       "      <td>0.351365</td>\n",
       "      <td>0.406875</td>\n",
       "      <td>-0.380615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184192</td>\n",
       "      <td>0.375116</td>\n",
       "      <td>-0.270579</td>\n",
       "      <td>0.727125</td>\n",
       "      <td>-1.118740</td>\n",
       "      <td>0.518312</td>\n",
       "      <td>0.038660</td>\n",
       "      <td>0.753666</td>\n",
       "      <td>-0.448771</td>\n",
       "      <td>0.952512</td>\n",
       "      <td>0.652654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.506676</td>\n",
       "      <td>0.094789</td>\n",
       "      <td>0.195305</td>\n",
       "      <td>0.081837</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>-1.602100</td>\n",
       "      <td>-0.538454</td>\n",
       "      <td>-0.693432</td>\n",
       "      <td>-1.032664</td>\n",
       "      <td>-0.254963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152952</td>\n",
       "      <td>0.358675</td>\n",
       "      <td>-0.110059</td>\n",
       "      <td>0.527310</td>\n",
       "      <td>-0.172935</td>\n",
       "      <td>1.296611</td>\n",
       "      <td>2.816321</td>\n",
       "      <td>0.654237</td>\n",
       "      <td>-0.020243</td>\n",
       "      <td>0.565185</td>\n",
       "      <td>0.944671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328299</td>\n",
       "      <td>-0.296977</td>\n",
       "      <td>-0.574391</td>\n",
       "      <td>0.176358</td>\n",
       "      <td>1.056336</td>\n",
       "      <td>-1.736760</td>\n",
       "      <td>-1.355283</td>\n",
       "      <td>-0.860753</td>\n",
       "      <td>-0.482475</td>\n",
       "      <td>-0.350410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214775</td>\n",
       "      <td>0.369537</td>\n",
       "      <td>-0.655319</td>\n",
       "      <td>0.250008</td>\n",
       "      <td>-0.768095</td>\n",
       "      <td>0.821194</td>\n",
       "      <td>-0.396885</td>\n",
       "      <td>0.483380</td>\n",
       "      <td>-0.304995</td>\n",
       "      <td>0.899381</td>\n",
       "      <td>0.705668</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.081934</td>\n",
       "      <td>0.326207</td>\n",
       "      <td>1.926577</td>\n",
       "      <td>0.211026</td>\n",
       "      <td>1.431870</td>\n",
       "      <td>-1.325838</td>\n",
       "      <td>-0.460970</td>\n",
       "      <td>0.283895</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>-0.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149145</td>\n",
       "      <td>-0.002320</td>\n",
       "      <td>0.515949</td>\n",
       "      <td>0.194529</td>\n",
       "      <td>-0.273838</td>\n",
       "      <td>0.460839</td>\n",
       "      <td>1.463139</td>\n",
       "      <td>-0.068498</td>\n",
       "      <td>-2.382287</td>\n",
       "      <td>2.049596</td>\n",
       "      <td>0.740805</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.080564</td>\n",
       "      <td>3.488676</td>\n",
       "      <td>-2.145503</td>\n",
       "      <td>1.398764</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>-2.292208</td>\n",
       "      <td>-1.472586</td>\n",
       "      <td>-0.278045</td>\n",
       "      <td>-0.357981</td>\n",
       "      <td>-0.359650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "6870    0.097919  0.438841 -0.163548  0.178571 -0.138751 -0.897668 -0.278711   \n",
       "184192  0.375116 -0.270579  0.727125 -1.118740  0.518312  0.038660  0.753666   \n",
       "152952  0.358675 -0.110059  0.527310 -0.172935  1.296611  2.816321  0.654237   \n",
       "214775  0.369537 -0.655319  0.250008 -0.768095  0.821194 -0.396885  0.483380   \n",
       "149145 -0.002320  0.515949  0.194529 -0.273838  0.460839  1.463139 -0.068498   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "6870    0.267664 -0.073018 -0.959436  ...  0.163835  0.066132 -0.431794   \n",
       "184192 -0.448771  0.952512  0.652654  ... -0.506676  0.094789  0.195305   \n",
       "152952 -0.020243  0.565185  0.944671  ... -0.328299 -0.296977 -0.574391   \n",
       "214775 -0.304995  0.899381  0.705668  ... -1.081934  0.326207  1.926577   \n",
       "149145 -2.382287  2.049596  0.740805  ... -2.080564  3.488676 -2.145503   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "6870    0.051063  0.226166  0.039451  0.572728  0.351365  0.406875 -0.380615  \n",
       "184192  0.081837  0.049967 -1.602100 -0.538454 -0.693432 -1.032664 -0.254963  \n",
       "152952  0.176358  1.056336 -1.736760 -1.355283 -0.860753 -0.482475 -0.350410  \n",
       "214775  0.211026  1.431870 -1.325838 -0.460970  0.283895  0.018107 -0.381700  \n",
       "149145  1.398764  0.307966 -2.292208 -1.472586 -0.278045 -0.357981 -0.359650  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6870      1\n",
       "184192    0\n",
       "152952    0\n",
       "214775    1\n",
       "149145    1\n",
       "         ..\n",
       "48101     0\n",
       "79536     1\n",
       "247056    0\n",
       "187676    0\n",
       "208217    0\n",
       "Name: Class, Length: 688, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting The Artificial Neural Network To The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 16, input_dim = 29, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 24, activation = 'relu', init = 'uniform'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 20, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 24, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 1, activation = 'sigmoid', init = 'uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "688/688 [==============================] - 0s 601us/step - loss: 0.6926 - accuracy: 0.5581\n",
      "Epoch 2/5\n",
      "688/688 [==============================] - 0s 128us/step - loss: 0.5952 - accuracy: 0.8881\n",
      "Epoch 3/5\n",
      "688/688 [==============================] - 0s 125us/step - loss: 0.2871 - accuracy: 0.9012\n",
      "Epoch 4/5\n",
      "688/688 [==============================] - 0s 129us/step - loss: 0.2262 - accuracy: 0.9201\n",
      "Epoch 5/5\n",
      "688/688 [==============================] - 0s 125us/step - loss: 0.2036 - accuracy: 0.9288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a41835550>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the ANN\n",
    "# Optimizer = 'adam': The algorithm used to find the optimal set of weights in the ANN.\n",
    "# Loss: The loss function within the stochastic gradient descent algorithm (within the adam algorithm).\n",
    "# Loss = 'binary_crossentropy': Binary outcomes\n",
    "# Loss = 'categorical_crossentropy': Three or more categories.\n",
    "# metrics = 'accuracy': The criterion we use to evaluate our model.\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 15, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Predicting the test set results\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 0s 233us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17701289541012533, 0.9358108043670654]\n"
     ]
    }
   ],
   "source": [
    "# From the below, we observe that we have achieved 99.94% accuracy in our model.\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148   1]\n",
      " [ 18 129]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9314079422382673"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a function of precision_score and recall_score, and it balances them out.\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923076923076923"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8775510204081632"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist (Frauds), how many did we predict as true.\n",
    "# Moreover the confusion matrix, this metric gives us a clearer picture of the reliabilty of the model.\n",
    "# This is due to Fraud transactions potentially having devastating consequences to people.\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15298 269017]\n",
      " [     0    492]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting for the whole dataset\n",
    "\n",
    "X = X_ds_scaled\n",
    "y = ds.Class\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "y_pred = y_pred > 0.5\n",
    "y_expected = y\n",
    "cm_all = confusion_matrix(y_expected, y_pred)\n",
    "print(cm_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05544105306400475"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist (Frauds), how many did we predict as true.\n",
    "# Moreover the confusion matrix, this metric gives us a clearer picture of the reliabilty of the model.\n",
    "# This is due to Fraud transactions potentially having devastating consequences to people.\n",
    "\n",
    "recall_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018255420041631263"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE : Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in /Users/mohitgoel/anaconda3/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/mohitgoel/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/mohitgoel/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /Users/mohitgoel/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/mohitgoel/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/mohitgoel/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resample, y_resample = SMOTE().fit_sample(X, y.values.ravel())\n",
    "\n",
    "y_resample = pd.DataFrame(y_resample)\n",
    "X_resample = pd.DataFrame(X_resample)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resample, y_resample, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting The Artificial Neural Network To The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 16, input_dim = 29, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 24, activation = 'relu', init = 'uniform'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 20, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 24, activation = 'relu', init = 'uniform'),\n",
    "    Dense(units = 1, activation = 'sigmoid', init = 'uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "398041/398041 [==============================] - 52s 129us/step - loss: 0.0467 - accuracy: 0.9836s - loss: 0.0\n",
      "Epoch 2/5\n",
      "398041/398041 [==============================] - 51s 128us/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 3/5\n",
      "398041/398041 [==============================] - 51s 129us/step - loss: 0.0199 - accuracy: 0.9943\n",
      "Epoch 4/5\n",
      "398041/398041 [==============================] - 51s 127us/step - loss: 0.0181 - accuracy: 0.9949\n",
      "Epoch 5/5\n",
      "398041/398041 [==============================] - 51s 127us/step - loss: 0.0161 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a414c7d68>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the ANN\n",
    "# Optimizer = 'adam': The algorithm used to find the optimal set of weights in the ANN.\n",
    "# Loss: The loss function within the stochastic gradient descent algorithm (within the adam algorithm).\n",
    "# Loss = 'binary_crossentropy': Binary outcomes\n",
    "# Loss = 'categorical_crossentropy': Three or more categories.\n",
    "# metrics = 'accuracy': The criterion we use to evaluate our model.\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 15, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Predicting the test set results\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170589/170589 [==============================] - 3s 18us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.012624782326397474, 0.9970924258232117]\n"
     ]
    }
   ],
   "source": [
    "# From the below, we observe that we have achieved 99.94% accuracy in our model.\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84872   455]\n",
      " [   41 85221]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970983631492121"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a function of precision_score and recall_score, and it balances them out.\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946892945515664"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995191292721259"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist (Frauds), how many did we predict as true.\n",
    "# Moreover the confusion matrix, this metric gives us a clearer picture of the reliabilty of the model.\n",
    "# This is due to Fraud transactions potentially having devastating consequences to people.\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[282907   1408]\n",
      " [     0    492]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting for the whole dataset\n",
    "\n",
    "X = X_ds_scaled\n",
    "y = ds.Class\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "y_pred = y_pred > 0.5\n",
    "y_expected = y\n",
    "cm_all = confusion_matrix(y_expected, y_pred)\n",
    "print(cm_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950563012847297"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Negatives)\n",
    "# Of all the positives that truly exist (Frauds), how many did we predict as true.\n",
    "# Moreover the confusion matrix, this metric gives us a clearer picture of the reliabilty of the model.\n",
    "# This is due to Fraud transactions potentially having devastating consequences to people.\n",
    "\n",
    "recall_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25894736842105265"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (True Positives)/(True Positives + False Positives)\n",
    "# Of all the positives predicted, how many of them are correct.\n",
    "\n",
    "precision_score(y_expected, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
